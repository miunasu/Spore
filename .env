# Spore 配置文件示例
# 复制此文件为 .env 并填入实际配置值

# ========== LLM SDK 选择 ==========
# 选择使用的 SDK：openai 或 anthropic
# openai: 使用 OpenAI SDK（支持 OpenAI、DeepSeek、第三方代理等）
# anthropic: 使用 Anthropic 官方 SDK
LLM_SDK=anthropic


#  ========== LLM 全局配置 =========
# 清理 SDK 的 x-stainless headers（某些第三方API代理需要开启）
# 对 OpenAI SDK 和 Anthropic SDK 都生效
CLEAN_SDK_HEADERS=false

# 清理 Authorization 头部（仅对 Anthropic SDK 有效）
# Anthropic SDK 会同时发送 x-api-key 和 Authorization 头部
# 有些第三方代理只接受 x-api-key，需要移除 Authorization
CLEAN_AUTH_HEADER=false

# 将 system prompt 作为第一条 user 消息发送（兼容不支持 system role 的模型）
# 启用后，system prompt 只会在对话开始时作为第一条 user 消息发送一次，后续不会重复
SYSTEM_AS_USER=true

# 系统提示文件（位于 prompt 目录下）
# 可选：prompt.md（默认，适用于 DeepSeek/GPT）、prompt_claude.md（Claude 专用）
#SYSTEM_PROMPT_FILE=prompt_claude.md

# Token 计算方式（gpt 或 claude）
# gpt: 使用 tiktoken (cl100k_base)，适用于 GPT/DeepSeek
# claude: 使用 anthropic tokenizer，适用于 Claude 模型
TOKENIZER_TYPE=gpt

# ========== OpenAI API 配置 ==========
# OpenAI API 密钥（LLM_SDK=openai 时必需）
# 从 https://platform.openai.com/ 获取
OPENAI_API_KEY=your-openai-api-key-here

# OpenAI API URL（可选，默认使用官方地址）
OPENAI_API_URL=https://api.openai.com/v1

# OpenAI 模型（LLM_SDK=openai 时使用）
# 可选：gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo 等
OPENAI_MODEL=gpt-4o-mini

# DeepSeek 官方 API 配置示例（取消注释以使用）
# OPENAI_MODEL=deepseek-chat
# OPENAI_API_URL=https://api.deepseek.com
# OPENAI_API_KEY=your-deepseek-api-key-here

# 本地 LLM 服务配置示例（取消注释以使用）
# OPENAI_API_KEY=local
# OPENAI_API_URL=http://localhost:11434/v1
# OPENAI_MODEL=llama3


# ========== Anthropic API 配置 ==========
# Anthropic API 密钥（LLM_SDK=anthropic 时必需）
# 从 https://console.anthropic.com/ 获取
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Anthropic API URL（可选，默认使用官方地址）
ANTHROPIC_API_URL=https://api.anthropic.com

# Anthropic 模型（LLM_SDK=anthropic 时使用）
# 可选：claude-opus-4-5, claude-sonnet-4-5, claude-sonnet-4, claude-3-5-sonnet-20241022 等
ANTHROPIC_MODEL=claude-sonnet-4-5


# ========== LLM 参数配置 ==========
# 主对话 temperature（0.0-2.0，数值越高越随机，默认 0.7）
TEMPERATURE_MAIN=0.7

# Coder 子 Agent temperature（代码生成，建议较低温度，默认 0.3）
# TEMPERATURE_CODER=0.3

# 监督 Agent temperature（循环检测，建议低温度，默认 0.1）
# TEMPERATURE_SUPERVISOR=0.1

# 角色选择器 temperature（角色推荐，建议低温度，默认 0.1）
# TEMPERATURE_CHARACTER_SELECTOR=0.1

# LLM 单次输出的最大 token 数
MAX_OUTPUT_TOKENS=8000

# API 请求超时时间（默认300秒）
# API_TIMEOUT=300


# ========== 对话管理配置 ==========
# 上下文最大 token 数（根据模型调整）
# 注意：需要为 completion (8000) + system prompt (~2000) 预留空间
CONTEXT_MAX_TOKENS=120000

# 上下文警告阈值（0.0-1.0，超过此比例时警告）
CONTEXT_WARNING_THRESHOLD=0.75

# 单条消息的最大token比例（0.0-1.0，相对于CONTEXT_MAX_TOKENS）
# 用于检测和删除超大消息
MAX_SINGLE_MESSAGE_RATIO=0.20

# 角色推荐触发频率（每 N 条用户消息触发一次）
# CHARACTER_RECOMMEND_INTERVAL=5

# 规则提醒间隔（每 N 次 LLM 回复提醒一次，0 表示禁用）
# 防止长对话中 LLM 遗忘工具格式和重要规则
RULE_REMINDER_INTERVAL=10

# 是否使用精简版规则提醒（节省 token）
# RULE_REMINDER_SHORT=false


# ========== 日志配置 ==========
# 是否记录到文件（true/false）
LOG_TO_FILE=true

# 日志文件最大大小（字节，默认10MB）
# LOG_FILE_MAX_SIZE=10485760

# 日志文件备份数量
# LOG_BACKUP_COUNT=5

# 日志监控显示行最大长度（字符数）
# LOG_MONITOR_MAX_LINE_LENGTH=200

# --- 日志文件名配置 ---
# 错误日志文件名
# LOG_ERROR_FILENAME=error.log

# LLM验证日志文件名
# LOG_LLM_VALIDATION_FILENAME=llm_validation.log

# 工具执行日志文件名
# LOG_TOOL_EXECUTION_FILENAME=tool_execution.log

# 一般日志文件名
# LOG_GENERAL_FILENAME=general.log

# --- 日志监控配置 ---
# 监控锁文件名
# LOG_MONITOR_LOCK_FILENAME=.monitor.lock

# 监控检查间隔（秒，影响日志刷新频率）
# LOG_MONITOR_CHECK_INTERVAL=0.5

# 监控显示的日志类型（逗号分隔）
# 可选值：error, llm_validation, tool_execution, general
# 默认：error,llm_validation,tool_execution（不包含general）
# 如果要显示所有日志：LOG_MONITOR_TYPES=error,llm_validation,tool_execution,general
# 如果只显示错误：LOG_MONITOR_TYPES=error
# LOG_MONITOR_TYPES=error,llm_validation,tool_execution


# ========== 工具配置 ==========
# Web 浏览器超时时间（秒）
# 用于 web_browser 工具访问网页的超时设置
# WEB_BROWSER_TIMEOUT=15

# Web 代理端口
# 用于访问国外网站时的代理设置（仅对非中文域名生效）
# 设置为 0 表示禁用代理，所有请求都直连
# 设置具体端口（如 7897）表示启用代理，访问非中文域名时使用代理
# 中文域名（如 .cn, baidu.com, taobao.com 等）始终直连，不使用代理
# 默认：7897（启用代理）
# 示例：
#   WEB_PROXY_PORT=0      # 禁用代理，所有请求直连
#   WEB_PROXY_PORT=7897   # 启用代理，非中文域名使用 http://127.0.0.1:7897
WEB_PROXY_PORT=0

# Web 内容最大长度（字符数）
# 网页内容超过此长度会被截断
WEB_MAX_CONTENT_LENGTH=20000

# 文件读取默认行数限制
# FILE_READ_DEFAULT_LIMIT=2000

# 文件最大行长度（字符数）
# FILE_MAX_LINE_LENGTH=2000

# IPC 通信检查间隔（秒）
# IPC_CHECK_INTERVAL=0.1


# ========== Chat进程并发配置 ==========
# 最大并发LLM请求数（线程池大小）
# CHAT_MAX_WORKERS=5

# 响应缓存过期时间（秒），超时未被取走的响应会被清理
# CHAT_RESPONSE_EXPIRE=300

# 响应缓存清理间隔（秒）
# CHAT_RESPONSE_CLEANUP_INTERVAL=60


# ========== 外部服务 API 配置 ==========


# ========== 多Agent配置 ==========
# 最大并发子Agent数量
# MULTI_AGENT_MAX_COUNT=5

# 子Agent最大迭代次数
# SUB_AGENT_MAX_ITERATIONS=100

# 多Agent等待超时时间（秒），留空表示无限等待
# MULTI_AGENT_TIMEOUT=

# 是否启用多Agent监控终端
# MULTI_AGENT_MONITOR_ENABLED=true

# 多Agent等待轮询间隔（秒），用于检查Ctrl+C中断信号
MULTI_AGENT_JOIN_INTERVAL=1.0


# ========== 工具执行配置 ==========
# 工具执行超时时间（秒）
# TOOL_EXECUTION_TIMEOUT=120

# Shell 命令执行超时时间（秒）
# SHELL_COMMAND_TIMEOUT=60

# 是否限制写工具的返回值（不在messages中添加arguments字段）
# 写工具包括：write_text_file, report_output, Edit, MultiEdit
# 启用此选项可节省token，因为写入的内容无需再次返回给LLM（默认true）
LIMIT_WRITE_TOOL_RETURN=true


# ========== 目录路径配置 ==========
# Skills 目录路径（相对于项目根目录）
# SKILLS_DIR=skills

# Characters 目录路径
# CHARACTERS_DIR=characters

# Prompt 目录路径
# PROMPT_DIR=prompt

# 日志目录路径
# LOG_DIR=logs

# Output 目录路径
# OUTPUT_DIR=output

# Web 上传目录路径
# UPLOAD_DIR=uploads


# ========== 桌面模式配置 ==========
# 启动模式: cli 或 desktop
# cli: 命令行模式（默认）
# desktop: 桌面 GUI 模式（Tauri + React）
LAUNCH_MODE=desktop

# 桌面模式 API 服务器主机地址
# DESKTOP_API_HOST=127.0.0.1

# 桌面模式 API 服务器端口
# DESKTOP_API_PORT=8765


# ========== 上下文处理模式配置 ==========
# 上下文处理模式（新对话的默认模式）
# strong_context: 强上下文关联模式 - 适合需要上下文强关联的任务和精确推理
# long_context: 长上下文处理模式 - 适合大文本处理、大项目编程和信息检索汇总报告。偏向多agent
# auto: 自动选择模式 - 根据任务自动判断使用哪种模式
# 默认：strong_context
# 注意：每个对话可以独立设置模式，此配置只影响新建对话的默认模式
CONTEXT_MODE=strong_context